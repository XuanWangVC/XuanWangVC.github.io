## Papers in 2023

<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPR 2023</div><img src='images/pub/next3d.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars](https://arxiv.org/pdf/2211.11208.pdf)

Jingxiang Sun, **Xuan Wang**, Lizhen Wang, Xiaoyu Li, Yong Zhang, Hongwen Zhang, Yebin Liu

[**Project**](https://mrtornado24.github.io/Next3D/) <strong><span class='show_paper_citations' data=''></span></strong>
- We propose a 3D representation called Generative Texture-Rasterized Tri-planes that learns Generative Neural Textures on top of parametric mesh templates and then projects them into three orthogonal-viewed feature planes through rasterization, forming a tri-plane feature representation for volume rendering.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPR 2023</div><img src='images/pub/uv_volumes.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[UV Volumes for Real-time Rendering of Editable Free-view Human Performance](https://arxiv.org/pdf/2203.14402.pdf)

Yue Chen, **Xuan Wang**$^\star$, Xingyu Chen, Qi Zhang, Xiaoyu Li, Yu Guo, Jue Wang, Fei Wang

[**Project**](https://github.com/fanegg/UV-Volumes) <strong><span class='show_paper_citations' data=''></span></strong>
- We propose the UV Volumes, a new approach that can render an editable free-view video of a human performer in real-time.
</div>
</div>
